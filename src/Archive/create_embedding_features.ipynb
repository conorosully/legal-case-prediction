{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used to create embedding feature sets from various word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same process as for n-gram features initially. i.e. get a balanced dataset.\n",
    "<br>\n",
    "Then stopwords are removed from the documents. This is done for three variations of stopwords as with n-gram feature selection. \n",
    "<br>\n",
    "Then for each document a mean embedding vector is created using the various differnet embeddings. This is done by cycling through the document word by word adding the vector associated to that word to a list. Then after all the words have been cycled throught the average by column is taken for all the vectors. \n",
    "\n",
    "<br>\n",
    "These features are then used in the same way as the n-gram features to fit models. \n",
    "<br> \n",
    "The embeddings included are:\n",
    "<ul>\n",
    "    <li> law2vec 100 dimensions \n",
    "    <li> law2vec 200 dimensions\n",
    "    <li> various wiki \n",
    "    <li> custom echt2vec 100,200 and 500 \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import nltk\n",
    "import json\n",
    "\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/conorosully/miniconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "embed_path = \"/Users/conorosully/Documents/Legal-Case-Prediction/data/embeddings/{}\"\n",
    "#embeddings = gensim.models.KeyedVectors.load_word2vec_format(embed_path.format(\"echt2vec_100.txt\"), binary=False)\n",
    "\n",
    "embeddings = Word2Vec.load(embed_path.format('echt2vec_500.txt'))\n",
    "embeddings.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8703\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>37</th>\n",
       "      <th>41</th>\n",
       "      <th>46</th>\n",
       "      <th>P1</th>\n",
       "      <th>P4</th>\n",
       "      <th>P12</th>\n",
       "      <th>P7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HUDOC-ECHR-1999-001-58225</td>\n",
       "      <td>1999-03-25</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HUDOC-ECHR-1999-001-58226</td>\n",
       "      <td>1999-03-25</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HUDOC-ECHR-1999-001-58227</td>\n",
       "      <td>1999-03-25</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HUDOC-ECHR-1999-001-58239</td>\n",
       "      <td>1999-04-29</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HUDOC-ECHR-1999-001-58251</td>\n",
       "      <td>1999-05-20</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id        date  2  3  5  6  7  8  9  10  ...  19  \\\n",
       "0  HUDOC-ECHR-1999-001-58225  1999-03-25 -1 -1  0 -1 -1 -1 -1  -1  ...  -1   \n",
       "1  HUDOC-ECHR-1999-001-58226  1999-03-25 -1 -1 -1  0 -1 -1 -1  -1  ...  -1   \n",
       "2  HUDOC-ECHR-1999-001-58227  1999-03-25 -1 -1 -1  2 -1  2 -1  -1  ...  -1   \n",
       "3  HUDOC-ECHR-1999-001-58239  1999-04-29 -1 -1  0 -1 -1 -1 -1  -1  ...  -1   \n",
       "4  HUDOC-ECHR-1999-001-58251  1999-05-20  0 -1 -1 -1 -1 -1 -1  -1  ...  -1   \n",
       "\n",
       "   34  35  37  41  46  P1  P4  P12  P7  \n",
       "0  -1  -1  -1   2  -1  -1  -1   -1  -1  \n",
       "1  -1  -1  -1   2  -1  -1  -1   -1  -1  \n",
       "2  -1   2  -1   2  -1   2  -1   -1  -1  \n",
       "3  -1   2  -1   2  -1  -1  -1   -1  -1  \n",
       "4  -1   2  -1   2  -1  -1  -1   -1  -1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.read_csv('/Users/conorosully/Documents/Legal-Case-Prediction/data/clean/target.csv')\n",
    "print(len(target))\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8703\n",
      "HUDOC-ECHR-1999-001-58225\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#Open cases\n",
    "path = \"/Users/conorosully/Documents/Legal-Case-Prediction/data/clean/{}.json\"\n",
    "\n",
    "with open(path.format('text_alpha'), 'r') as readfile:\n",
    "    text = json.load(readfile)\n",
    "    readfile.close()\n",
    "    \n",
    "print(len(text.keys()))\n",
    "print(list(text.keys())[0])\n",
    "print(len(text['HUDOC-ECHR-2012-001-110881']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureSet(article,part,stop_words = None):\n",
    "    \"\"\"\n",
    "    returns the feature set corrisponding to article and part \n",
    "    \"\"\"\n",
    "    df = target[['id',article]]\n",
    "    \n",
    "    #Get balanced dataset\n",
    "    nvLen = len(df[df[article] == 0]) \n",
    "    vLen = len(df[df[article] == 1])\n",
    "    minLen = min(nvLen,vLen)\n",
    "\n",
    "    nvID = df[df[article] == 0][0:minLen]['id']\n",
    "    vID = df[df[article] == 1][0:minLen]['id']\n",
    "    \n",
    "    nvCorpus = []\n",
    "    vCorpus = []\n",
    "    for ID in nvID:\n",
    "        nvCorpus.append(text[ID][part])\n",
    "\n",
    "    for ID in vID:\n",
    "        vCorpus.append(text[ID][part])\n",
    "        \n",
    "    corpus = nvCorpus + vCorpus\n",
    "    targets = ['nonviolation']*minLen + ['violation']*minLen\n",
    "    \n",
    "    \n",
    "    docs_vectors = pd.DataFrame() # creating empty final dataframe\n",
    "    #stopwords = nltk.corpus.stopwords.words('english') # removing stop words\n",
    "    for doc in corpus:\n",
    "        temp = pd.DataFrame()  # creating a temporary dataframe(store value for 1st doc & for 2nd doc remove the details of 1st & proced through 2nd and so on..)\n",
    "        for word in doc.split(' '): # looping through each word of a single document and spliting through space\n",
    "            if word not in stop_words: # if word is not present in stopwords then (try)\n",
    "                try:\n",
    "                    word_vec = embeddings[word] # if word is present in embeddings(goole provides weights associate with words(300)) then proceed\n",
    "                    temp = temp.append(pd.Series(word_vec), ignore_index = True) # if word is present then append it to temporary dataframe\n",
    "                except:\n",
    "                    pass\n",
    "        doc_vector = temp.mean() # take the average of each column(w0, w1, w2,........w300)\n",
    "        docs_vectors = docs_vectors.append(doc_vector, ignore_index = True) # append each document value to the final dataframe\n",
    "    \n",
    "    docs_vectors['target'] = targets\n",
    "        \n",
    "    return docs_vectors    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/conorosully/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "article = '6'\n",
    "part = 'procedure'\n",
    "features = featureSet(article,part,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011321</td>\n",
       "      <td>0.014460</td>\n",
       "      <td>-0.016181</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>-0.019687</td>\n",
       "      <td>-0.016117</td>\n",
       "      <td>-0.036738</td>\n",
       "      <td>0.025446</td>\n",
       "      <td>-0.013823</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020419</td>\n",
       "      <td>0.021468</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>-0.000320</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.018111</td>\n",
       "      <td>0.028388</td>\n",
       "      <td>0.027493</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>nonviolation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009993</td>\n",
       "      <td>0.006624</td>\n",
       "      <td>-0.014365</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>-0.016161</td>\n",
       "      <td>-0.016264</td>\n",
       "      <td>-0.036446</td>\n",
       "      <td>0.028414</td>\n",
       "      <td>-0.012915</td>\n",
       "      <td>-0.001069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025133</td>\n",
       "      <td>0.031530</td>\n",
       "      <td>0.010492</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.014982</td>\n",
       "      <td>0.014008</td>\n",
       "      <td>0.027591</td>\n",
       "      <td>0.024884</td>\n",
       "      <td>-0.003666</td>\n",
       "      <td>nonviolation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010176</td>\n",
       "      <td>0.015237</td>\n",
       "      <td>-0.013580</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>-0.015260</td>\n",
       "      <td>-0.018593</td>\n",
       "      <td>-0.036681</td>\n",
       "      <td>0.024620</td>\n",
       "      <td>-0.016559</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019496</td>\n",
       "      <td>0.020421</td>\n",
       "      <td>0.009352</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.011334</td>\n",
       "      <td>0.016373</td>\n",
       "      <td>0.025633</td>\n",
       "      <td>0.024931</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>nonviolation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012798</td>\n",
       "      <td>0.017465</td>\n",
       "      <td>-0.016626</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>-0.016920</td>\n",
       "      <td>-0.018701</td>\n",
       "      <td>-0.036673</td>\n",
       "      <td>0.027618</td>\n",
       "      <td>-0.014540</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019341</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.008825</td>\n",
       "      <td>-0.000664</td>\n",
       "      <td>0.009478</td>\n",
       "      <td>0.022386</td>\n",
       "      <td>0.028831</td>\n",
       "      <td>0.028553</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>nonviolation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006456</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>-0.008301</td>\n",
       "      <td>0.002175</td>\n",
       "      <td>-0.015984</td>\n",
       "      <td>-0.013255</td>\n",
       "      <td>-0.031683</td>\n",
       "      <td>0.024989</td>\n",
       "      <td>-0.013704</td>\n",
       "      <td>-0.003329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>0.024906</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>0.016650</td>\n",
       "      <td>0.012128</td>\n",
       "      <td>0.020167</td>\n",
       "      <td>0.023561</td>\n",
       "      <td>-0.002069</td>\n",
       "      <td>nonviolation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.011321  0.014460 -0.016181  0.001387 -0.019687 -0.016117 -0.036738   \n",
       "1  0.009993  0.006624 -0.014365  0.000621 -0.016161 -0.016264 -0.036446   \n",
       "2  0.010176  0.015237 -0.013580  0.001344 -0.015260 -0.018593 -0.036681   \n",
       "3  0.012798  0.017465 -0.016626  0.001322 -0.016920 -0.018701 -0.036673   \n",
       "4  0.006456  0.004688 -0.008301  0.002175 -0.015984 -0.013255 -0.031683   \n",
       "\n",
       "          7         8         9  ...       491       492       493       494  \\\n",
       "0  0.025446 -0.013823  0.003356  ...  0.020419  0.021468  0.007250 -0.000320   \n",
       "1  0.028414 -0.012915 -0.001069  ...  0.025133  0.031530  0.010492  0.002114   \n",
       "2  0.024620 -0.016559  0.002768  ...  0.019496  0.020421  0.009352  0.000780   \n",
       "3  0.027618 -0.014540  0.003669  ...  0.019341  0.020002  0.008825 -0.000664   \n",
       "4  0.024989 -0.013704 -0.003329  ...  0.019678  0.024906  0.004739  0.003573   \n",
       "\n",
       "        495       496       497       498       499        target  \n",
       "0  0.012819  0.018111  0.028388  0.027493  0.003604  nonviolation  \n",
       "1  0.014982  0.014008  0.027591  0.024884 -0.003666  nonviolation  \n",
       "2  0.011334  0.016373  0.025633  0.024931  0.002685  nonviolation  \n",
       "3  0.009478  0.022386  0.028831  0.028553  0.006616  nonviolation  \n",
       "4  0.016650  0.012128  0.020167  0.023561 -0.002069  nonviolation  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#import autosklearn.classification\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import json\n",
    "\n",
    "import functions \n",
    "classif = functions.classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTest(features):\n",
    "    \"\"\"Return train test split from features\"\"\"\n",
    "    #print(features['target'])\n",
    "    X = features.drop(columns='target')\n",
    "    X=(X-X.mean())/X.std() #Normalise\n",
    "    y = features['target']\n",
    "    return train_test_split(X, y, test_size=0.10, random_state=90)\n",
    "\n",
    "def k_fold(X_train, y_train,C,cv = 10,kernel='linear'):\n",
    "    \"\"\"\n",
    "    Returns k_fold accuracy for given C parameter\n",
    "    \"\"\"\n",
    "    model = SVC(kernel=kernel, C=C)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv)\n",
    "    accuracy = scores.mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.5066666666666666\n",
      "0.001 0.728818620992534\n",
      "0.01 0.766453667105841\n",
      "0.1 0.7865107597716292\n",
      "1 0.7536144049187528\n",
      "10 0.7179995608256476\n"
     ]
    }
   ],
   "source": [
    "#Article 3 - ECHR 100\n",
    "X_train, X_test, y_train, y_test = trainTest(features)\n",
    "hyper_c = [0.0001,0.001,0.01,0.1,1,10]\n",
    "for C in hyper_c:\n",
    "    accuracy = k_fold(X_train, y_train,C)\n",
    "    print(C, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.6403293807641633\n",
      "0.001 0.7643785682916117\n",
      "0.01 0.7930764163372859\n",
      "0.1 0.7822134387351778\n",
      "1 0.7643302591128677\n",
      "10 0.7688735177865613\n"
     ]
    }
   ],
   "source": [
    "#Article 3 - ECHR 200\n",
    "X_train, X_test, y_train, y_test = trainTest(features)\n",
    "hyper_c = [0.0001,0.001,0.01,0.1,1,10]\n",
    "for C in hyper_c:\n",
    "    accuracy = k_fold(X_train, y_train,C)\n",
    "    print(C, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.722538427755819\n",
      "0.001 0.7929776021080369\n",
      "0.01 0.817584541062802\n",
      "0.1 0.7490206411945542\n",
      "1 0.7179468599033817\n",
      "10 0.7179468599033817\n"
     ]
    }
   ],
   "source": [
    "#Article 3 - ECHR 500\n",
    "X_train, X_test, y_train, y_test = trainTest(features)\n",
    "hyper_c = [0.0001,0.001,0.01,0.1,1,10]\n",
    "for C in hyper_c:\n",
    "    accuracy = k_fold(X_train, y_train,C)\n",
    "    print(C, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.5044444444444445\n",
      "0.001 0.6957180500658762\n",
      "0.01 0.7198243302591129\n",
      "0.1 0.7094005270092227\n",
      "1 0.7291106719367588\n",
      "10 0.7225340360122969\n"
     ]
    }
   ],
   "source": [
    "#Artcile 3 - 100\n",
    "X_train, X_test, y_train, y_test = trainTest(features)\n",
    "hyper_c = [0.0001,0.001,0.01,0.1,1,10]\n",
    "for C in hyper_c:\n",
    "    accuracy = k_fold(X_train, y_train,C)\n",
    "    print(C, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.5199538866930171\n",
      "0.001 0.7528173034694774\n",
      "0.01 0.7798858146684233\n",
      "0.1 0.7669433465085639\n",
      "1 0.7510430390865173\n",
      "10 0.7533135704874836\n"
     ]
    }
   ],
   "source": [
    "#Artcile 3 - 200\n",
    "X_train, X_test, y_train, y_test = trainTest(features)\n",
    "hyper_c = [0.0001,0.001,0.01,0.1,1,10]\n",
    "for C in hyper_c:\n",
    "    accuracy = k_fold(X_train, y_train,C)\n",
    "    print(C, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.7372532587441001\n",
      "0.001 0.8293370410277061\n",
      "0.01 0.8414597867531552\n",
      "0.1 0.8367444484351136\n",
      "1 0.8221235438592671\n",
      "10 0.8148208008184499\n"
     ]
    }
   ],
   "source": [
    "#Article 6 - ECHR 100\n",
    "X_train, X_test, y_train, y_test = trainTest(features)\n",
    "hyper_c = [0.0001,0.001,0.01,0.1,1,10]\n",
    "for C in hyper_c:\n",
    "    accuracy = k_fold(X_train, y_train,C)\n",
    "    print(C, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.795410004970197\n",
      "0.001 0.8498924333286171\n",
      "0.01 0.8595607361696107\n",
      "0.1 0.8329070573168916\n",
      "1 0.8099563565916783\n",
      "10 0.8063720101725783\n"
     ]
    }
   ],
   "source": [
    "#Article 6 - ECHR 200\n",
    "X_train, X_test, y_train, y_test = trainTest(features)\n",
    "hyper_c = [0.0001,0.001,0.01,0.1,1,10]\n",
    "for C in hyper_c:\n",
    "    accuracy = k_fold(X_train, y_train,C)\n",
    "    print(C, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.8353607746251491\n",
      "0.001 0.8655844697670538\n",
      "0.01 0.8632343284610892\n",
      "0.1 0.83177606541795\n",
      "1 0.8269571510976155\n",
      "10 0.8269571510976155\n"
     ]
    }
   ],
   "source": [
    "#Article 6 - ECHR 500\n",
    "X_train, X_test, y_train, y_test = trainTest(features)\n",
    "hyper_c = [0.0001,0.001,0.01,0.1,1,10]\n",
    "for C in hyper_c:\n",
    "    accuracy = k_fold(X_train, y_train,C)\n",
    "    print(C, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.774883998505313\n",
      "0.001 0.8256333373240026\n",
      "0.01 0.8390641155407538\n",
      "0.1 0.8282802392950301\n",
      "1 0.8221378739891817\n",
      "10 0.8075915223677003\n"
     ]
    }
   ],
   "source": [
    "#Article 6 - 100\n",
    "X_train, X_test, y_train, y_test = trainTest(features)\n",
    "hyper_c = [0.0001,0.001,0.01,0.1,1,10]\n",
    "for C in hyper_c:\n",
    "    accuracy = k_fold(X_train, y_train,C)\n",
    "    print(C, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.808810671774723\n",
      "0.001 0.8451326534684357\n",
      "0.01 0.8559459155501863\n",
      "0.1 0.8486876140515086\n",
      "1 0.7991563362755449\n",
      "10 0.7771595868569128\n"
     ]
    }
   ],
   "source": [
    "#Article 6 - 200\n",
    "X_train, X_test, y_train, y_test = trainTest(features)\n",
    "hyper_c = [0.0001,0.001,0.01,0.1,1,10]\n",
    "for C in hyper_c:\n",
    "    accuracy = k_fold(X_train, y_train,C)\n",
    "    print(C, accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
